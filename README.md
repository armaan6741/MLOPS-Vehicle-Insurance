# ğŸš— Vehicle Data Intelligence System â€” MLOps Project

An end-to-end **Machine Learning Operations (MLOps)** project that automates the entire lifecycle â€” from **data ingestion** to **deployment** â€” using **AWS Cloud Services**, **Docker**, **MongoDB**, and **GitHub Actions (CI/CD)**.
This project demonstrates how modern ML applications are built, trained, validated, containerized, and deployed seamlessly in production.

---

## ğŸ§  Project Overview

This project is designed to **predict and analyze vehicle data** using a scalable and modular architecture.
It follows an enterprise-level **MLOps architecture** â€” ensuring automation, reliability, versioning, and scalability.

**Key Highlights:**

* ğŸ“¦ Modular Python package structure using `setup.py` and `pyproject.toml`
* â˜ï¸ Data hosted on **MongoDB Atlas**
* ğŸªµ Centralized **Logging** and custom **Exception Handling**
* âš™ï¸ ML Pipeline with modular **Data Ingestion**, **Validation**, **Transformation**, **Training**, and **Evaluation**
* ğŸš€ Automated deployment via **Docker**, **GitHub Actions**, and **AWS EC2**
* ğŸ§° Model & artifact management via **AWS S3**
* ğŸ” Continuous Integration and Continuous Deployment (CI/CD)
* ğŸ“ˆ Interactive EDA & Feature Engineering notebooks
* ğŸ§© Fully reproducible environment using **Conda**

---

## ğŸ—ï¸ Project Setup

### 1ï¸âƒ£ Project Template Initialization

```bash
python template.py
```

This script auto-generates the project folder structure.

---

### 2ï¸âƒ£ Package Setup

Define package metadata and dependencies using:

* `setup.py`
* `pyproject.toml`


---

### 3ï¸âƒ£ Virtual Environment Setup

```bash
conda create -n vehicle python=3.10 -y
conda activate vehicle
pip install -r requirements.txt
pip list  # verify installed packages
```

---

## ğŸ—„ï¸ MongoDB Atlas Setup

1. Sign up at [MongoDB Atlas](https://www.mongodb.com/atlas/database)
2. Create a new project and cluster (M0 tier - free)
3. Create a DB user with username/password
4. Add IP Access: `0.0.0.0/0`
5. Get the **Connection String** for Python (save it securely)
6. Create a `notebook/` folder and use Jupyter Notebook to push data into MongoDB
7. Verify data in MongoDB â†’ *Browse Collections*

---

## ğŸ§¾ Logging, Exception Handling & Notebooks

* Implemented **custom logger** and **exception classes**
* Integrated with demo scripts for validation
* Includes EDA and Feature Engineering notebooks

---

## ğŸ§© Data Pipeline Components

### ğŸ§  Data Ingestion

* Reads data from MongoDB
* Transforms JSON â†’ Pandas DataFrame
* Stores metadata as artifacts

**Key Files:**

* `constants/__init__.py`
* `configuration/mongo_db_connections.py`
* `data_access/proj1_data.py`
* `entity/config_entity.py`
* `entity/artifact_entity.py`
* `components/data_ingestion.py`

Set MongoDB connection URL in environment:

```bash
export MONGODB_URL="mongodb+srv://<username>:<password>@cluster-url"
```

---

### âœ… Data Validation

Defines schema in `config/schema.yaml`
Validates structure, datatypes, and missing values.

---

### ğŸ”„ Data Transformation

Applies preprocessing pipelines and feature transformations.
Stores transformers and encoders as serialized objects.

---

### ğŸ§® Model Trainer

Trains ML model using transformed data and saves the model artifact.

---

## â˜ï¸ AWS Integration

### AWS Services Used

* **IAM** â†’ User roles & credentials
* **S3** â†’ Model & artifact storage
* **EC2** â†’ Deployment
* **ECR** â†’ Docker image registry

Set AWS credentials:

```bash
export AWS_ACCESS_KEY_ID="..."
export AWS_SECRET_ACCESS_KEY="..."
```

**Key Constants**

```python
MODEL_EVALUATION_CHANGED_THRESHOLD_SCORE = 0.02
MODEL_BUCKET_NAME = "my-model-mlopsproj"
MODEL_PUSHER_S3_KEY = "model-registry"
```

---

## ğŸ§± Model Evaluation & Pusher

* Evaluates new model performance
* Pushes approved models to AWS S3 for versioning

---

## ğŸ”® Prediction Pipeline & Web App

* Flask-based API (`app.py`)
* Routes:

  * `/` â†’ Home
  * `/predict` â†’ Run predictions
  * `/training` â†’ Trigger model training

Add static assets in:

```
static/
templates/
```

---

## ğŸ³ Dockerization & CI/CD

### Docker Setup

* `Dockerfile`
* `.dockerignore`

### GitHub Actions Workflow

* Located in `.github/workflows/aws.yaml`
* Automates:

  * CI (Build & Test)
  * CD (Push Docker image â†’ ECR â†’ Deploy on EC2)

---

## ğŸ§° AWS Deployment Workflow

1. Create **IAM user** (`usvisa-user`) for GitHub Actions

2. Create **ECR repository**

   ```
   vehicleproj
   ```

3. Launch **EC2 instance**:

   * Ubuntu Server 24.04 (t2.medium)
   * Port: `5080`
   * Add Security Group rules for inbound traffic

4. Install Docker on EC2:

   ```bash
   curl -fsSL https://get.docker.com -o get-docker.sh
   sudo sh get-docker.sh
   sudo usermod -aG docker ubuntu
   newgrp docker
   ```

5. Configure **Self-Hosted Runner** for GitHub Actions:

   * Settings â†’ Actions â†’ Runners â†’ New self-hosted runner
   * Follow terminal commands on EC2

6. Add GitHub Repository Secrets:

   * `AWS_ACCESS_KEY_ID`
   * `AWS_SECRET_ACCESS_KEY`
   * `AWS_DEFAULT_REGION`
   * `ECR_REPO`

7. Commit & push â€” GitHub Actions will automatically deploy to EC2.

---

## ğŸŒ Accessing the Application

Once deployed, open your app in browser:

```
http://<EC2-Public-IP>:5080
```

---

## ğŸ§¾ Project Architecture

```
ğŸ“¦ vehicle-mlops
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ configuration/
â”‚   â”œâ”€â”€ data_access/
â”‚   â”œâ”€â”€ entity/
â”‚   â”œâ”€â”€ pipeline/
â”‚   â””â”€â”€ aws_storage/
â”œâ”€â”€ notebook/
â”œâ”€â”€ templates/
â”œâ”€â”€ static/
â”œâ”€â”€ setup.py
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ app.py
â”œâ”€â”€ Dockerfile
â””â”€â”€ .github/workflows/aws.yaml
```

---

## ğŸ§  Tech Stack

| Category                   | Tools/Tech                              |
| -------------------------- | --------------------------------------- |
| **Language**               | Python 3.10                             |
| **Data Storage**           | MongoDB Atlas                           |
| **ML/EDA**                 | Pandas, NumPy, Scikit-learn, Matplotlib |
| **Pipeline Management**    | Custom Modular Architecture             |
| **Cloud Platform**         | AWS (EC2, S3, ECR, IAM)                 |
| **Orchestration**          | GitHub Actions (CI/CD)                  |
| **Containerization**       | Docker                                  |
| **Environment Management** | Conda                                   |
| **Web Framework**          | Flask                                   |

---

## ğŸ Final Output

âœ… Fully automated ML pipeline
âœ… Model deployed on AWS EC2
âœ… Continuous delivery with GitHub Actions
âœ… Production-grade modular codebase

---

<!-- ### ğŸŒŸ Author

**Armaan Haider**
<!-- *MLOps Enthusiast | Data Scientist | Cloud Developer*

ğŸ“§ Reach me on [LinkedIn](#) or [GitHub](#)

---

Would you like me to **add emojis, color highlights (for GitHub Markdown), and badges** (like â€œBuilt with Pythonâ€, â€œAWS Certifiedâ€, â€œCI/CD Enabledâ€, etc.) to make it even more visually appealing for recruiters? --> -->
